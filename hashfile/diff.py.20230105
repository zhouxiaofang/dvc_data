import reprlib
from typing import TYPE_CHECKING, Dict, List, Optional, Tuple

from attrs import asdict, define, field

if TYPE_CHECKING:
    from .db import HashFileDB
    from .hash_info import HashInfo
    from .meta import Meta
    from .obj import HashFile

# add by zhoufang, 20221223
import math
from datetime import datetime
from concurrent.futures import ProcessPoolExecutor
# import multiprocessing
from multiprocessing import Process
from multiprocessing import Queue, JoinableQueue
import os


ADD = "add"
MODIFY = "modify"
DELETE = "delete"
UNCHANGED = "unchanged"


@define(hash=True, order=True)
class TreeEntry:
    in_cache: bool = field(default=False, eq=False)
    key: Tuple[str, ...] = ()
    meta: Optional["Meta"] = field(default=None, eq=False)
    oid: Optional["HashInfo"] = None

    def __bool__(self):
        return bool(self.oid)


@define(hash=True, order=True)
class Change:
    old: TreeEntry = field(factory=TreeEntry)
    new: TreeEntry = field(factory=TreeEntry)
    typ: str = field(init=False)

    @typ.default
    def _(self):
        if not self.old and not self.new:
            return UNCHANGED

        if self.old and not self.new:
            return DELETE

        if not self.old and self.new:
            return ADD

        if self.old != self.new:
            return MODIFY

        return UNCHANGED

    def __bool__(self):
        return self.typ != UNCHANGED


@define
class DiffResult:
    added: List[Change] = field(factory=list, repr=reprlib.repr)
    modified: List[Change] = field(factory=list, repr=reprlib.repr)
    deleted: List[Change] = field(factory=list, repr=reprlib.repr)
    unchanged: List[Change] = field(factory=list, repr=reprlib.repr)

    def __bool__(self):
        return bool(self.added or self.modified or self.deleted)

    @property
    def stats(self) -> Dict[str, int]:
        return {k: len(v) for k, v in asdict(self).items()}
    


ROOT = ("",)

# create by zhoufang, date 20221223
def slice_keys(process_jobs, old_keys, new_keys ):  
    src_old_keys = list(old_keys)
    src_new_keys = list(new_keys)
    print("开启的进程数目为：", process_jobs)
    old_length = len(src_old_keys)
    new_length = len(src_new_keys)
    n = process_jobs
    
    old_keys_list = []
    for i in range(n):
        one_thread_list = src_old_keys[math.floor(i / n * old_length): math.floor((i + 1) / n * old_length)]
        one_thread_set = set(one_thread_list)
        old_keys_list.append(one_thread_set)
    print("主进程成功获取所有文件图片，old_keys_list写文件的切片数目：", len(old_keys_list))
    
    new_keys_list = []
    for j in range(n):
        one_slice_list = src_new_keys[math.floor(j / n * new_length): math.floor((j + 1) / n * new_length)]
        one_slice_set = set(one_slice_list)
        new_keys_list.append(one_slice_set)
    print("主进程成功获取所有文件图片，new_keys_list写文件的切片数目：", len(new_keys_list))
    
    return old_keys_list, new_keys_list

def diff(  # noqa: C901
    old: Optional["HashFile"],
    new: Optional["HashFile"],
    cache: "HashFileDB",
) -> DiffResult:
    # t1 = datetime.now()
    from .tree import Tree

    if old is None and new is None:
        return DiffResult()

    def _get_keys(obj):
        if not obj:
            return []
        return [ROOT] + (
            [key for key, _, _ in obj] if isinstance(obj, Tree) else []
        )

    old_keys = set(_get_keys(old))
    new_keys = set(_get_keys(new))

    def _get(obj, key):
        if not obj or key == ROOT:
            return None, (obj.hash_info if obj else None)
        if not isinstance(obj, Tree):
            # obj is not a Tree and key is not a ROOT
            # hence object does not exist for a given key
            return None, None
        return obj.get(key, (None, None))

    def _in_cache(oid, cache):
        from dvc_objects.errors import ObjectFormatError

        if not oid:
            return False

        try:
            cache.check(oid.value)
            return True
        except (FileNotFoundError, ObjectFormatError):
            return False
    
    # t2 = datetime.now()
    # time_diff = t2-t1
    # print("success call in odiff(), step1.1 _get_keys() func cost: [odiff比对中核心耗时1] #{}".format(time_diff))
    
    # t3 = datetime.now()
    ret = DiffResult()
    for key in old_keys | new_keys:
        old_meta, old_oid = _get(old, key)
        new_meta, new_oid = _get(new, key)

        change = Change(
            old=TreeEntry(_in_cache(old_oid, cache), key, old_meta, old_oid),
            new=TreeEntry(_in_cache(new_oid, cache), key, new_meta, new_oid),
        )

        if change.typ == ADD:
            ret.added.append(change)
        elif change.typ == MODIFY:
            ret.modified.append(change)
        elif change.typ == DELETE:
            ret.deleted.append(change)
        else:
            assert change.typ == UNCHANGED
            ret.unchanged.append(change)
    
    # t4 = datetime.now()
    # time_ret = t4-t3
    # print("success call in odiff(), step1.2 for _get() func cost: [odiff中核心耗时2] #{}".format(time_ret))
    return ret
    # dvc源码，注释 end by zhoufang 20221223
    
    
    
    # 旧方案一：加速版的数据比对操作，create by zhoufang at 20221226
    # def target_func(result_queue, old_keys_slice, new_keys_slice):
    # def target_func(old_keys_slice, new_keys_slice):
    #     local_process_ret = DiffResult() #进程池共享全局变量获取该变量进行展开遍历
    #     for key in old_keys_slice | new_keys_slice:
    #         old_meta, old_oid = _get(old, key)
    #         new_meta, new_oid = _get(new, key)

    #         change = Change(
    #             old=TreeEntry(_in_cache(old_oid, cache), key, old_meta, old_oid),
    #             new=TreeEntry(_in_cache(new_oid, cache), key, new_meta, new_oid),
    #         )

    #         if change.typ == ADD:
    #             local_process_ret.added.append(change)
    #         elif change.typ == MODIFY:
    #             local_process_ret.modified.append(change)
    #         elif change.typ == DELETE:
    #             local_process_ret.deleted.append(change)
    #         else:
    #             assert change.typ == UNCHANGED
    #             local_process_ret.unchanged.append(change)
    #     # result_queue.put(local_process_ret)
    #     return local_process_ret

    
    # old_keys_slice_list, new_keys_slice_list = slice_keys(4, old_keys, new_keys) 
          
    # time1 = datetime.now()
    # # global_result = []
    
    # print("odiff并行进程池操作, starting ...")
    # # result_queue = JoinableQueue() # Queue()
    # process_list = []
    # for i in range(4):
    #     # t = Process(target=target_func, args=(result_queue, old_keys_slice_list[i], new_keys_slice_list[i], ))
    #     t = Process(target=target_func, args=(old_keys_slice_list[i], new_keys_slice_list[i], ))
    #     t.start()
    #     process_list.append(t) 
    # for t in process_list:
    #     t.join()
        
    # # global_result = [result_queue.get() for kth in process_list]
    
    # time2 = datetime.now()
    # print("odiff并行进程池操作, 主进程执行的总时间：", time2 - time1)
    
    # global_share_ret = DiffResult()
    # for k in range(global_result.__len__()):
    #     global_share_ret.added.extend(global_result[k].added)
    #     global_share_ret.modified.extend(global_result[k].modified)
    #     global_share_ret.deleted.extend(global_result[k].deleted)
    #     global_share_ret.unchanged.extend(global_result[k].unchanged)
    
    # return global_share_ret
    # 旧方案一 end, create by zhoufang at 20221226
